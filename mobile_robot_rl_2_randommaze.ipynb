{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Jan 29 2025 23:16:28\n"
     ]
    }
   ],
   "source": [
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "from stable_baselines3 import PPO # Or A2C, DQN for discrete actions\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import time\n",
    "from stable_baselines3.common.callbacks import ProgressBarCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MazeCarEnv(gym.Env):\n",
    "    metadata = {'render_modes': ['human'], \"render_fps\": 500}\n",
    "\n",
    "    def __init__(self, render_mode=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # --- Define Action Space ---\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        # --- Define Observation Space ---\n",
    "        low = np.array([-6, -6, -np.pi, -6, -6], dtype=np.float32)\n",
    "        high = np.array([6, 6, np.pi, 6, 6], dtype=np.float32)\n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"state\": spaces.Box(\n",
    "                low=np.array([-6, -6, -np.pi, -6, -6], dtype=np.float32),\n",
    "                high=np.array([6, 6, np.pi, 6, 6], dtype=np.float32),\n",
    "                dtype=np.float32\n",
    "            ),\n",
    "            \"camera\": spaces.Box(\n",
    "                low=0,\n",
    "                high=255,\n",
    "                shape=(64, 64, 4),  # RGBA image from PyBullet\n",
    "                dtype=np.uint8\n",
    "            )\n",
    "        })\n",
    "\n",
    "        # --- PyBullet Setup ---\n",
    "        self.render_mode = render_mode\n",
    "        self.client = p.connect(p.DIRECT if render_mode is None else p.GUI)\n",
    "        p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "        p.setGravity(0, 0, -9.81, physicsClientId=self.client)\n",
    "\n",
    "        self.planeId = p.loadURDF(\"plane.urdf\", physicsClientId=self.client)\n",
    "\n",
    "        self.goal_area_1 = np.array([4.5, 4.5])   # Upper goal\n",
    "        self.goal_area_2 = np.array([4.5, -4.5])  # Lower goal\n",
    "        self.goal_radius = 0.5\n",
    "        self.target_goal_pos = None  # Will be set in reset()\n",
    "        self.correct_goal_index = None  # Random selection of the target goal\n",
    "\n",
    "        self.goal_spheres = []\n",
    "\n",
    "        # Car (robot) loading\n",
    "        self.start_pos = [-4.5, 0.0, 0.1]  # Start near the left side of the maze\n",
    "        self.start_orn = p.getQuaternionFromEuler([0, 0, 0])\n",
    "        self.carId = p.loadURDF(\"urdf/simple_two_wheel_car.urdf\",\n",
    "                                self.start_pos, self.start_orn,\n",
    "                                physicsClientId=self.client)\n",
    "        \n",
    "        self.left_wheel_joint_index = 1\n",
    "        self.right_wheel_joint_index = 0\n",
    "\n",
    "        self.step_counter = 0\n",
    "        self.max_steps_per_episode = 200\n",
    "\n",
    "        self.action_repeat = 50\n",
    "\n",
    "    def _get_obs(self):\n",
    "        pos, orn_quat = p.getBasePositionAndOrientation(self.carId, physicsClientId=self.client)\n",
    "        euler = p.getEulerFromQuaternion(orn_quat)\n",
    "        yaw = euler[2]\n",
    "\n",
    "        camera_image = self._get_camera_image()\n",
    "\n",
    "        return {\n",
    "            \"state\": np.array([pos[0], pos[1], yaw, self.target_goal_pos[0], self.target_goal_pos[1]], dtype=np.float32),\n",
    "            \"camera\": camera_image\n",
    "        }\n",
    "\n",
    "    def _get_info(self):\n",
    "        car_pos, _ = p.getBasePositionAndOrientation(self.carId, physicsClientId=self.client)\n",
    "        dist_goal1 = np.linalg.norm(np.array(car_pos[:2]) - self.goal_area_1)\n",
    "        dist_goal2 = np.linalg.norm(np.array(car_pos[:2]) - self.goal_area_2)\n",
    "\n",
    "        return {\n",
    "            \"distance_goal1\": dist_goal1,\n",
    "            \"distance_goal2\": dist_goal2,\n",
    "            \"target_goal_index\": self.correct_goal_index\n",
    "        }\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.step_counter = 0\n",
    "\n",
    "        # Randomly generate a maze\n",
    "        maze = self.generate_maze(21, 21)  # You can adjust the size of the maze here\n",
    "        self.create_maze_walls(maze)\n",
    "\n",
    "        # Reset the car's position\n",
    "        start_x = self.start_pos[0] + self.np_random.uniform(-0.3, 0.3)\n",
    "        start_y = self.start_pos[1] + self.np_random.uniform(-0.3, 0.3)\n",
    "        start_yaw = self.np_random.uniform(-np.pi/6, np.pi/6)\n",
    "        start_orn = p.getQuaternionFromEuler([0, 0, start_yaw])\n",
    "        p.resetBasePositionAndOrientation(self.carId, [start_x, start_y, self.start_pos[2]], start_orn, physicsClientId=self.client)\n",
    "        p.resetBaseVelocity(self.carId,\n",
    "                            linearVelocity=[0, 0, 0],\n",
    "                            angularVelocity=[0, 0, 0],\n",
    "                            physicsClientId=self.client)\n",
    "\n",
    "        # Remove all existing multibodies\n",
    "        multibodies = [p.getBodyUniqueId(i) for i in range(p.getNumBodies(physicsClientId=self.client))]\n",
    "        for body_id in multibodies:\n",
    "            p.removeBody(body_id, physicsClientId=self.client)\n",
    "        self.goal_spheres.clear()\n",
    "\n",
    "        # Randomly choose the \"correct\" goal\n",
    "        self.correct_goal_index = self.np_random.integers(0, 2)\n",
    "        \n",
    "        if self.correct_goal_index == 0:\n",
    "            self.target_goal_pos = self.goal_area_1\n",
    "        else:\n",
    "            self.target_goal_pos = self.goal_area_2\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            left_vel, right_vel = 10.0, 10.0\n",
    "        elif action == 1:\n",
    "            left_vel, right_vel = 2.0, 10.0\n",
    "        elif action == 2:\n",
    "            left_vel, right_vel = 10.0, 2.0\n",
    "\n",
    "        p.setJointMotorControl2(\n",
    "            bodyUniqueId=self.carId,\n",
    "            jointIndex=self.left_wheel_joint_index,\n",
    "            controlMode=p.VELOCITY_CONTROL,\n",
    "            targetVelocity=left_vel,\n",
    "            force=20.0\n",
    "        )\n",
    "        p.setJointMotorControl2(\n",
    "            bodyUniqueId=self.carId,\n",
    "            jointIndex=self.right_wheel_joint_index,\n",
    "            controlMode=p.VELOCITY_CONTROL,\n",
    "            targetVelocity=right_vel,\n",
    "            force=20.0\n",
    "        )\n",
    "\n",
    "        # Step through the simulation multiple times to simulate the action\n",
    "        for _ in range(self.action_repeat):\n",
    "            p.stepSimulation()\n",
    "\n",
    "        self.step_counter += 1\n",
    "\n",
    "        # Observation + reward + termination check\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        terminated = False\n",
    "        reward = -0.005\n",
    "\n",
    "        car_pos, _ = p.getBasePositionAndOrientation(self.carId, physicsClientId=self.client)\n",
    "        curr_dist_to_goal = np.linalg.norm(np.array(car_pos[:2]) - self.target_goal_pos)\n",
    "        reward = 0.1 * (self.prev_dist_to_goal - curr_dist_to_goal)\n",
    "        self.prev_dist_to_goal = curr_dist_to_goal\n",
    "\n",
    "        in_goal_1 = np.linalg.norm(car_pos[:2] - self.goal_area_1) < self.goal_radius\n",
    "        in_goal_2 = np.linalg.norm(car_pos[:2] - self.goal_area_2) < self.goal_radius\n",
    "\n",
    "        if in_goal_1:\n",
    "            if self.correct_goal_index == 0:\n",
    "                reward = 20.0\n",
    "                terminated = True\n",
    "            else:\n",
    "                reward = -15.0\n",
    "                terminated = True\n",
    "        elif in_goal_2:\n",
    "            if self.correct_goal_index == 1:\n",
    "                reward = 20.0\n",
    "                terminated = True\n",
    "            else:\n",
    "                reward = -15.0\n",
    "                terminated = True\n",
    "\n",
    "        contacts = p.getContactPoints(bodyA=self.carId, bodyB=self.mazeId, physicsClientId=self.client)\n",
    "        if len(contacts) > 0:\n",
    "            reward -= 1.0  # Penalty for collision with the maze wall\n",
    "            terminated = True \n",
    "\n",
    "        truncated = (self.step_counter >= self.max_steps_per_episode)\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def generate_maze(self, width, height):\n",
    "        # Create an empty maze\n",
    "        maze = np.zeros((height, width), dtype=int)\n",
    "\n",
    "        # Directions (Up, Down, Right, Left)\n",
    "        directions = [(-1, 0), (1, 0), (0, 1), (0, -1)]\n",
    "\n",
    "        def is_valid_move(x, y):\n",
    "            return 0 <= x < height and 0 <= y < width and maze[x][y] == 0\n",
    "\n",
    "        def carve(x, y):\n",
    "            maze[x][y] = 1\n",
    "            random.shuffle(directions)\n",
    "\n",
    "            for dx, dy in directions:\n",
    "                nx, ny = x + dx * 2, y + dy * 2\n",
    "                if is_valid_move(nx, ny):\n",
    "                    maze[x + dx][y + dy] = 1\n",
    "                    carve(nx, ny)\n",
    "\n",
    "        # Start carving from a random position\n",
    "        start_x = random.randint(0, (height - 1) // 2) * 2 + 1  # Ensures odd indices for carving\n",
    "        start_y = random.randint(0, (width - 1) // 2) * 2 + 1   # Ensures odd indices for carving\n",
    "        carve(start_x, start_y)\n",
    "\n",
    "        # Ensure start and end are open (avoid out-of-bounds errors)\n",
    "        maze[start_x][start_y] = 0\n",
    "        maze[height - 2][width - 2] = 0  # Set bottom-right corner as the goal\n",
    "\n",
    "        return maze\n",
    "\n",
    "\n",
    "    # def create_maze_walls(self, maze):\n",
    "    #     wall_urdf = \"urdf/wall.urdf\"  # Path to a simple wall URDF\n",
    "    #     maze_height, maze_width = maze.shape\n",
    "    #     wall_objects = []\n",
    "\n",
    "    #     for row in range(maze_height):\n",
    "    #         for col in range(maze_width):\n",
    "    #             if maze[row][col] == 1:  # Wall detected\n",
    "    #                 wall_pos = [col * 1.0, row * 1.0, 0.5]\n",
    "    #                 wall_id = p.loadURDF(wall_urdf, wall_pos, useFixedBase=True)\n",
    "    #                 wall_objects.append(wall_id)\n",
    "\n",
    "    #     self.mazeId = wall_objects\n",
    "\n",
    "    def create_maze_walls(self, maze):\n",
    "        wall_urdf = \"urdf/wall.urdf\"  # Path to the wall URDF\n",
    "\n",
    "        # Print the URDF path to ensure it's correct\n",
    "        print(f\"Loading wall URDF from path: {wall_urdf}\")\n",
    "\n",
    "        maze_height, maze_width = maze.shape\n",
    "        wall_objects = []\n",
    "\n",
    "        for row in range(maze_height):\n",
    "            for col in range(maze_width):\n",
    "                if maze[row][col] == 1:  # Wall detected\n",
    "                    wall_pos = [col * 1.0, row * 1.0, 0.5]  # Position of the wall (scaled by cell size)\n",
    "                    try:\n",
    "                        # Attempt to load the URDF\n",
    "                        wall_id = p.loadURDF(wall_urdf, wall_pos, useFixedBase=True)\n",
    "                        wall_objects.append(wall_id)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to load URDF at position {wall_pos}: {e}\")\n",
    "\n",
    "        self.mazeId = wall_objects\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        # In PyBullet, rendering happens automatically in GUI mode\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        p.disconnect(physicsClientId=self.client)\n",
    "\n",
    "    def _get_camera_image(self):\n",
    "        car_pos, car_orn = p.getBasePositionAndOrientation(self.carId, physicsClientId=self.client)\n",
    "        car_euler = p.getEulerFromQuaternion(car_orn)\n",
    "\n",
    "        camera_distance = 0.1\n",
    "        camera_height = 0.2\n",
    "        camera_yaw = car_euler[2] * 180 / np.pi\n",
    "        target_pos = [\n",
    "            car_pos[0] + camera_distance * np.cos(car_euler[2]),\n",
    "            car_pos[1] + camera_distance * np.sin(car_euler[2]),\n",
    "            car_pos[2] + camera_height\n",
    "        ]\n",
    "\n",
    "        width, height, rgba, _, _ = p.getCameraImage(\n",
    "            width=64,\n",
    "            height=64,\n",
    "            viewMatrix=p.computeViewMatrix(\n",
    "                cameraEyePosition=[car_pos[0], car_pos[1], car_pos[2] + camera_height],\n",
    "                cameraTargetPosition=target_pos,\n",
    "                cameraUpVector=[0, 0, 1]\n",
    "            ),\n",
    "            projectionMatrix=p.computeProjectionMatrixFOV(\n",
    "                fov=70,\n",
    "                aspect=1.0,\n",
    "                nearVal=0.01,\n",
    "                farVal=10.0\n",
    "            ),\n",
    "            physicsClientId=self.client\n",
    "        )\n",
    "\n",
    "        rgba_image = np.reshape(rgba, (height, width, 4)).astype(np.uint8)\n",
    "        return rgba_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Intel\n",
      "GL_RENDERER=Mesa Intel(R) Graphics (RPL-P)\n",
      "GL_VERSION=4.6 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.3\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.6 (Core Profile) Mesa 23.2.1-1ubuntu3.1~22.04.3\n",
      "Vendor = Intel\n",
      "Renderer = Mesa Intel(R) Graphics (RPL-P)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "Environment check passed!\n"
     ]
    }
   ],
   "source": [
    "# env = MazeCarEnv(render_mode=None) \n",
    "env = MazeCarEnv(render_mode=\"human\")\n",
    "\n",
    "p.resetDebugVisualizerCamera(cameraDistance=9, cameraYaw=-92, cameraPitch=-85, cameraTargetPosition=[0, 0, 0])\n",
    "\n",
    "try:\n",
    "    check_env(env)\n",
    "    print(\"Environment check passed!\")\n",
    "except Exception as e:\n",
    "    print(f\"Environment check failed: {e}\")\n",
    "    env.close()\n",
    "    exit()\n",
    "\n",
    "model = PPO(\"MultiInputPolicy\", \n",
    "            env, \n",
    "            ent_coef=0.05,\n",
    "            # verbose=1, \n",
    "            tensorboard_log=\"./ppo_mazecar_tensorboard/\",\n",
    "            batch_size=128, # after n_steps the data is split into batches\n",
    "            learning_rate=0.0003,\n",
    "            n_steps=512,   # number of steps collected before a training\n",
    "            device=\"cuda\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a067402e45a4e04a9d869319dabaf3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numActiveThreads = 0\n",
      "stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n",
      "finished\n",
      "numActiveThreads = 0\n",
      "btShutDownExampleBrowser stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n",
      "stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n",
      "finished\n",
      "numActiveThreads = 0\n",
      "btShutDownExampleBrowser stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n"
     ]
    }
   ],
   "source": [
    "# eval_env = MazeCarEnv(render_mode='human')\n",
    "# eval_freq = 1000 \n",
    "# eval_callback = EvalCallback(eval_env, eval_freq, verbose=1)\n",
    "\n",
    "model.learn(total_timesteps=5000, progress_bar=True)\n",
    "\n",
    "model.save(\"ppo_mazecar_model_2\")\n",
    "env.close()\n",
    "# check_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- To evaluate ---\n",
    "eval_env = MazeCarEnv(render_mode=\"human\")  # Render during evaluation\n",
    "model = PPO.load(\"ppo_mazecar_model_2_2\", env=eval_env)\n",
    "\n",
    "# Set the camera to the same position as for training\n",
    "p.resetDebugVisualizerCamera(cameraDistance=9, cameraYaw=-92, cameraPitch=-85, cameraTargetPosition=[0, 0, 0])\n",
    "\n",
    "\n",
    "print(\".......................\")\n",
    "obs, info = eval_env.reset()\n",
    "print(\".......................\")\n",
    "\n",
    "for _ in range(500):  # Max steps for evaluation\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = eval_env.step(action)\n",
    "    time.sleep(1./120.0)  # Adjust sleep time for rendering speed\n",
    "    if terminated or truncated:\n",
    "        print(f\"Eval episode finished, Reached goal: {info.get('target_goal_index')}, Reward: {reward}\")\n",
    "        obs, info = eval_env.reset()  # Reset for next evaluation episode\n",
    "\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb22712c1f294f60885e54af11bf8709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo_mazecar_model_2\u001b[39m\u001b[38;5;124m\"\u001b[39m, env\u001b[38;5;241m=\u001b[39menv)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Continue training the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Save the updated model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo_mazecar_model_2_2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/masterthesis/ve_pybullet/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/masterthesis/ve_pybullet/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:324\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 324\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/masterthesis/ve_pybullet/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:218\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 218\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m~/masterthesis/ve_pybullet/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:222\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/masterthesis/ve_pybullet/lib/python3.10/site-packages/stable_baselines3/common/vec_env/vec_transpose.py:97\u001b[0m, in \u001b[0;36mVecTransposeImage.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m---> 97\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Transpose the terminal observations\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, done \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dones):\n",
      "File \u001b[0;32m~/masterthesis/ve_pybullet/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:59\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 59\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/masterthesis/ve_pybullet/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "Cell \u001b[0;32mIn[2], line 180\u001b[0m, in \u001b[0;36mMazeCarEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# Jetzt die Simulation mehrmals updaten,\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_repeat):\n\u001b[0;32m--> 180\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstepSimulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# Beobachtung + Reward + Done bestimmen\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X connection to :0 broken (explicit kill or server shutdown).\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load the previously saved model\n",
    "model = PPO.load(\"ppo_mazecar_model_2\", env=env)\n",
    "\n",
    "# Continue training the model\n",
    "model.learn(total_timesteps=50000, progress_bar=True)\n",
    "\n",
    "# Save the updated model\n",
    "model.save(\"ppo_mazecar_model_2_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m      3\u001b[0m check_env\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# car_pos, _ = p.getBasePositionAndOrientation(eval_env.carId, physicsClientId=eval_env.client)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# p.resetDebugVisualizerCamera(cameraDistance=3, cameraYaw=50, cameraPitch=-35, cameraTargetPosition=car_pos)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env.close()\n",
    "\n",
    "check_env.close()\n",
    "\n",
    "# car_pos, _ = p.getBasePositionAndOrientation(eval_env.carId, physicsClientId=eval_env.client)\n",
    "# p.resetDebugVisualizerCamera(cameraDistance=3, cameraYaw=50, cameraPitch=-35, cameraTargetPosition=car_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numActiveThreads = 0\n",
      "stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n",
      "finished\n",
      "numActiveThreads = 0\n",
      "btShutDownExampleBrowser stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n"
     ]
    }
   ],
   "source": [
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~/masterthesis/mt_start$   tensorboard --logdir=./ppo_mazecar_tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True if GPU is available\n",
    "print(torch.cuda.get_device_name(0))  # Prints the name of the GPU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve_pybullet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
